# general
run_name: 'test' #'augmented_version'
seed: 0 # run seed

# channel
memory_length: 4 # Memory length of the channel. values: int. Tested with values <=4.
channel_type: 'ISI_AWGN' # Channel type. For this paper, we only used ISI AWGN. values: ['ISI_AWGN'].
channel_coefficients: 'time_decay' # The taps of the channel. values: ['time_decay','cost2100'].
fading_in_channel: False # If the channel is fading/non-fading. values: [True, False]
gamma: 0.5 # gamma value for time decay fading

# new
n_user: 4
n_ant: 4
iterations: 5
channel_mode: 'SED'

# validation hyperparameters
val_block_length: 11000 # coherence block time. values: int.
pilot_size: 1000 # pilot symbols
val_frames: 10 # number of validation frames. values: int.
val_snr: 12 # start SNR value. values: float.
eval_mode: 'by_word' # Type of evaluation per block - 'by_word'.

# online training hyperparameters
is_online_training: True # Whether to run the online training (as in ViterbiNet). values: [True, False].
online_total_words: 200 # Number of words per iteration trained on in the online training. values: int.
train_minibatch_size: 32 # the size of a given minibatch. values: int.
lr: 0.001 # learning rate. values: float.
loss_type: 'CrossEntropy' # Loss type. values: 'BCE','CrossEntropy','MSE'.
optimizer_type: 'Adam' # Optimizer type. values: 'Adam','RMSprop','SGD'.
from_scratch_flag: True

# augmentations
aug_type: ['no_aug']
# ['no_aug','full_knowledge_augmenter','partial_knowledge_augmenter','adaptive_augmenter','flipping_augmenter','border_smote_augmenter']
online_repeats_n: 25 # number of desired augmented words out of online_total_words. values: 0<=online_repeats_n<=online_total_words